# Claim_Identification_Corpus
314 persuasive essays annotated for claims. The essays were written by undergraduate students (N = 314) at a public university in the United States who were native speakers of English. 

The essays were structurally annotated by normed raters for argumentative elements. We used the modified Toulmin models as the basis for the annotation rubric. The rubric adopted six elements (i.e., micro-categories) as the building blocks of the argumentation framework: Final Claim, Primary Claim, Counterclaim, Rebuttal, Data, and Concluding Summary. 

The essays were coded by two annotators on the web-based text annotation platform ‘Tagtog’1. The two annotators were both native speakers of English and were undergraduate students majoring in applied linguistics at a public university in the United States. Before independent annotation, a norming process was conducted to help ensure consistency in annotations. Once normed, the two annotators worked independently and coded the 314 essays in the opposite order to avoid recency effects.
The two annotators made decisions on both the boundary of an argumentative element and the category of the element. An argumentative element was inherently suprasentential (i.e., according to the annotation scheme derived from the norming session, it could contain one or more sentences, and the content could be over the span of paragraphs). Inter-rater reliability calculated using Fleiss’s Kappa for all the annotations was 0.584 (p < 0.001), indicating fair to good agreement [16]. Disagreements of either boundary or category of the argumentative elements between the two annotators were adjudicated by an expert adjudicator who had years of experience teaching and conducting writing research. In the case of disagreement, the expert adjudicator compared the annotations from both annotators and made the final decision for both the boundary and the category of the argumentative element. The current corpus focuses on the identification of claims versus non-claims, mainly because of the small sample size of the corpus and the distribution of micro-categories. Thus, we combined the categories of Final Claim, Primary Claim, Counterclaim, and Rebuttal into a single category of claims. The remaining categories of Data and Concluding summary were classified as non-claims as was any non-annotated text.

Additional information here

https://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_163.pdf

Please cite

Wan, Q., Crossley, S.A., Banawan, M., Balyan, R., Allen, L., & McNamara, D. S. (2021). Automated Claim Identification Using NLP Features in Student Argumentative Essays. Proceedings of the 14th International Conference on Educational Data Mining (EDM).

If used
